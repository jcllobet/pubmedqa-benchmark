{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.nomic import NomicEmbedding\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    ServiceContext,\n",
    "    Document,\n",
    "    get_response_synthesizer,\n",
    ")\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from typing import Annotated\n",
    "import os\n",
    "import re \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wv/b_h63k2j0997cxn743g60jn40000gn/T/ipykernel_64120/3871610202.py:8: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da85bf93e3b40a684401d272b725451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ad55d08db340bf9f8c2409929e0d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127517077b7e474c80068684692c06ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc77b422217f4c60b8d117ace17df95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e059fa2c144c648dfe8258e030928a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ffbf791964348669fb7e9d91cd70308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ee7521350d43d1a81b79d8382667d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928bccc3ca2448ecb5a7b66780572836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987f20e6def54a88aa20451c1efabac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860d00a72cbf4e8b92ead0063c3192cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6e0ea21f8f421f85879674a54e6641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\"./data/split/\").load_data()\n",
    "nomic_api_key = os.environ.get(\"NOMIC_API_KEY\")\n",
    "embed_model = NomicEmbedding(\n",
    "    api_key=nomic_api_key,\n",
    "    model_name=\"nomic-embed-text-v1\",\n",
    "    task_type=\"search_document\"\n",
    ")\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    embed_model=embed_model, chunk_size=1024,\n",
    ")\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=documents, service_context=service_context, show_progress=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wv/b_h63k2j0997cxn743g60jn40000gn/T/ipykernel_64120/3146419878.py:7: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "embed_model = NomicEmbedding(\n",
    "    api_key=nomic_api_key,\n",
    "    model_name=\"nomic-embed-text-v1\",\n",
    "    task_type=\"search_query\"\n",
    ")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents, embedding_model=embed_model)\n",
    "#search_query_retriever = index.as_retriever(service_context=service_context, similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=3,\n",
    ")\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The effectiveness of alternative medicine is being evaluated in the provided context through studies on homeopathic remedies, herbal products, and vitamin D deficiency. The studies investigate the impact of high potencies of homeopathic remedies on enzyme activities, the safety information provided with commonly used herbal products, and the possible relationships among vitamin D status, endothelial dysfunction, and inflammation.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the effectiveness of alternative medicine?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistral Eval + RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "open_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(payload):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {open_api_key}\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        resp = requests.post(\"https://api.openai.com/v1/chat/completions\", \n",
    "                             headers=headers, json=payload)\n",
    "        data = resp.json()\n",
    "        if 'choices' in data and data['choices']:\n",
    "            resp_dict = data['choices'][0]['message']['content']\n",
    "            return resp_dict\n",
    "        else:\n",
    "            print(\"Unexpected response structure:\", data)\n",
    "            return None\n",
    "    \n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err}\")\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(f\"An error occurred: {err}\")\n",
    "    except KeyError as key_err:\n",
    "        print(f\"Key error: {key_err} - the structure of the response might not be as expected.\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data as current dir (one level up) + data folder + file \n",
    "data = json.load(open('./data/test_set.json'))\n",
    "labels = json.load(open('./data/test_ground_truth.json'))\n",
    "len(data), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, question in data.items():\n",
    "#     print(idx, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4-turbo-2024-04-09\"\n",
    "#model = \"gpt-4-0125-preview\"\n",
    "#model = \"gpt-3.5-turbo\"\n",
    "run = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for i, qa in data.items():\n",
    "    question = qa[\"QUESTION\"]\n",
    "    context = qa[\"CONTEXTS\"]\n",
    "    context_labels = qa[\"LABELS\"]\n",
    "    meshes = qa[\"MESHES\"]\n",
    "    year = qa[\"YEAR\"]\n",
    "\n",
    "    system_prompt = \"You are expert doctor from Harvard with expertise in searching medically relevant information in VectorDatabases. Your goal is to provide the user with a medically relevant and related question to search through a medical vectorDB that would better help them decide about the answer to the original one. Your response MUST be a question. It will be used to search for in a similar qa database in order to obtain additional data that could better inform your answer.\"\n",
    "    query_prompt = f\"Help me come up with a question that helps me answer the following question: {question}, with a response of (yes / no/ maybe).\"\n",
    "\n",
    "    query_data = {\n",
    "        \"model\": model, \n",
    "        \"temperature\": 0.1,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": system_prompt},\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": query_prompt},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 240,\n",
    "    }\n",
    "\n",
    "    synthetic_query = prompt(query_data)\n",
    "    synthetic_context = query_engine.query(synthetic_query if synthetic_query else question)\n",
    "\n",
    "    results[i] = {\n",
    "        \"original_question\": question,\n",
    "        \"synthetic_query\": synthetic_query,\n",
    "        \"synthetic_context\": synthetic_context\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jcllobet/Code/Github/pubmedqa-benchmark'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get current directory\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the directory exists as current dir + rag folder\n",
    "directory_path = f\"{current_dir}/rag/{model}\"\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)\n",
    "\n",
    "def serialize_obj(obj):\n",
    "    \"\"\"Custom serializer function for non-serializable objects.\"\"\"\n",
    "    if isinstance(obj, (list, dict, str, int, float, bool, type(None))):\n",
    "        return obj\n",
    "    return str(obj)  # Convert non-serializable objects to string\n",
    "\n",
    "# Save the results with the run timestamp appended to the filename\n",
    "file_path = f\"{directory_path}/query_results_{run}.json\"\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(results, file, default=serialize_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, gt = {}, {}\n",
    "\n",
    "class_dict = { 'no': 0, 'yes': 1, 'maybe': 2}\n",
    "\n",
    "# Load synthetic queries and contexts from saved JSON\n",
    "# with open(file_path, 'r') as file:\n",
    "    # synthetic_data = json.load(file)\n",
    "synthetic_data = results\n",
    "total_items = len(data)\n",
    "\n",
    "for i, qa in data.items():\n",
    "\n",
    "    synthetic_query = synthetic_data[str(i)][\"synthetic_query\"]\n",
    "    synthetic_context = synthetic_data[str(i)][\"synthetic_context\"]\n",
    "\n",
    "    # Create the prompt using the combined context and the current question\n",
    "    text_prompt = f\"Answer the question: {question}. Given the original context: {context}. My previous doctor asked the following question {synthetic_query} to a medically relevant database and shared this complementary context {synthetic_context} that can be used to better inform your answer. The answer can only be one word and it should be either 'yes', 'no', or 'maybe'.\"\n",
    "    #text_prompt = f\"Answer the question {question} given context: {context}. Answer can only be one word and it should be either 'yes', 'no', or 'maybe'.\"\n",
    "    \n",
    "    prompt_data = {\n",
    "        \"model\": model, \n",
    "        \"temperature\": 0.1,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": text_prompt},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 10,\n",
    "    }\n",
    "    \n",
    "    resp = prompt(prompt_data)\n",
    "    #clean the respose for any non-alphabetical characters:\n",
    "    resp = re.sub(r'[^a-zA-Z]', '', resp).strip()\n",
    "    \n",
    "    try:\n",
    "        if not resp:\n",
    "            original_question = data[i][\"QUESTION\"]\n",
    "            synthetic_question = query_prompt  # Assuming query_prompt is accessible here\n",
    "            expected_answer = labels[i]  # Assuming labels[i] is accessible here\n",
    "            raise ValueError(f\"No response received for query of id{i}. Original Question: {original_question}, Synthetic Question: {synthetic_question}, Expected Answer: {expected_answer}\")\n",
    "\n",
    "        predictions.update({i: class_dict[resp.lower()]})\n",
    "        gt.update({i: class_dict[labels[i]]})\n",
    "        correct = 1 if resp.lower() == labels[i].lower() else 0\n",
    "\n",
    "    except KeyError as e:\n",
    "        original_question = data[i][\"QUESTION\"]\n",
    "        synthetic_question = query_prompt  # Assuming query_prompt is accessible here\n",
    "        synthetic_response = synthetic_query  # Assuming synthetic_query is accessible here\n",
    "        actual_response = resp\n",
    "        print(f\"KeyError processing query of id {i}: {e}\")\n",
    "        print(f\"Original Question: {original_question}\")\n",
    "        print(f\"Synthetic Question: {synthetic_question}\")\n",
    "        print(f\"Synthetic Response: {synthetic_response}\")\n",
    "        print(f\"Actual Response: {actual_response}\")\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(ve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions), len(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.548"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(list(gt.values()), list(predictions.values() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24351120365011236"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(list(gt.values()), list(predictions.values()), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
